{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmYJadiJbiqHOPR/GC53Ht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihrisikesa/DWS/blob/main/Kartu_Progress_Sahabat_Sehat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# AUTH (single source of truth)\n",
        "# =======================\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import google.auth\n",
        "from googleapiclient.discovery import build\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Scopes + creds\n",
        "SCOPES = [\n",
        "    \"https://www.googleapis.com/auth/drive\",\n",
        "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "    \"https://www.googleapis.com/auth/documents\",\n",
        "]\n",
        "creds, _ = default()\n",
        "creds = creds.with_scopes(SCOPES)\n",
        "\n",
        "# Clients\n",
        "gc        = gspread.authorize(creds)\n",
        "drive_svc = build(\"drive\", \"v3\", credentials=creds)\n",
        "docs_svc  = build(\"docs\",  \"v1\", credentials=creds)\n",
        "\n",
        "# If you need Colab Drive FS:\n",
        "from google.colab import drive as gdrive\n",
        "gdrive.mount('/content/drive')\n",
        "\n",
        "# =======================\n",
        "# CONFIG\n",
        "# =======================\n",
        "SHEET_ID         = \"1sYyHqoGWRdfhC6-bMQ1jjltibg7P6YALJsth1WE-UA4\"   # Sheet ID master data\n",
        "SHEET_TAB        = \"Lobar\"\n",
        "TEMPLATE_DOC_ID  = \"1J7HbsU6f7DibHDSTnPIfcTv9sv2silrSpFDTtWtJpiI\"   # Template Documents ID\n",
        "DEST_FOLDER_ID   = \"1LVDm5DF9ZlV8dMla5lOliv-xHZWKkwF2\"              # Folder di Google Drive (opsional)\n",
        "OUTPUT_TAB       = \"Laporan Kinerja Harian (LKH)\"\n",
        "SKIP_IF_HAS_LINK = True                  # True = jangan buat ulang jika link sudah ada\n",
        "FILTER_DATE      = None                  # contoh: \"2025-09-30\" untuk satu hari saja, None = semua\n",
        "\n",
        "# Optional: simple categorization for DWS score\n",
        "def kategori_dws(x):\n",
        "    if pd.isna(x): return \"\"\n",
        "    x = float(x)\n",
        "    if x >= 85: return \"Sangat Baik\"\n",
        "    if x >= 70: return \"Baik\"\n",
        "    if x >= 60: return \"Cukup\"\n",
        "    return \"Perlu Pendampingan\"\n",
        "\n",
        "# =======================\n",
        "# Helpers\n",
        "# =======================\n",
        "MONTH_ID = [\"Januari\",\"Februari\",\"Maret\",\"April\",\"Mei\",\"Juni\",\n",
        "            \"Juli\",\"Agustus\",\"September\",\"Oktober\",\"November\",\"Desember\"]\n",
        "\n",
        "def tanggal_id(dt: pd.Timestamp) -> str:\n",
        "    dt = pd.to_datetime(dt, errors=\"coerce\")\n",
        "    if pd.isna(dt): return \"\"\n",
        "    return f\"{dt.day} {MONTH_ID[dt.month-1]} {dt.year}\"\n",
        "\n",
        "def copy_template(new_name: str) -> str:\n",
        "    body = {\"name\": new_name}\n",
        "    if DEST_FOLDER_ID:\n",
        "        body[\"parents\"] = [DEST_FOLDER_ID]\n",
        "    file = drive_svc.files().copy(fileId=TEMPLATE_DOC_ID, body=body).execute()\n",
        "    return file[\"id\"]\n",
        "\n",
        "def replace_placeholders(doc_id: str, mapping: dict):\n",
        "    # push both UPPER and lower/space variants\n",
        "    requests = []\n",
        "    for k, v in mapping.items():\n",
        "        requests.append({\n",
        "            \"replaceAllText\": {\n",
        "                \"containsText\": {\"text\": f\"{{{{{k}}}}}\", \"matchCase\": True},\n",
        "                \"replaceText\": \"\" if v is None else str(v)\n",
        "            }\n",
        "        })\n",
        "    docs_svc.documents().batchUpdate(\n",
        "        documentId=doc_id, body={\"requests\": requests}\n",
        "    ).execute()\n",
        "\n",
        "def fmt_id(v):\n",
        "    if pd.isna(v):\n",
        "        return \"\"\n",
        "    s = str(v).strip().replace(\",\", \".\")\n",
        "    # remove trailing .0 / .000...\n",
        "    if re.fullmatch(r\"\\d+(?:\\.0+)?\", s):\n",
        "        return s.split(\".\")[0]\n",
        "    # scientific notation\n",
        "    try:\n",
        "        if \"e\" in s.lower():\n",
        "            return \"{:.0f}\".format(float(s))\n",
        "    except:\n",
        "        pass\n",
        "    return s\n",
        "\n",
        "# Quick permission check\n",
        "_ = docs_svc.documents().get(documentId=TEMPLATE_DOC_ID).execute()\n",
        "print(\"Template is accessible.\")\n",
        "\n",
        "# =======================\n",
        "# Read the source Sheet\n",
        "# =======================\n",
        "ws = gc.open_by_key(SHEET_ID).worksheet(SHEET_TAB)\n",
        "df = get_as_dataframe(ws, evaluate_formulas=True).dropna(how=\"all\")\n",
        "\n",
        "# Standardize expected columns (case-insensitive safety)\n",
        "df.columns = [str(c).strip().lower() for c in df.columns]\n",
        "\n",
        "# Ensure needed columns exist\n",
        "needed = [\n",
        "    \"id\",\"name\",\"date\",\"score_dws\",\"rank_dws\",\n",
        "    \"score_missmatch\",\"rank_missmatch\",\n",
        "    \"score_error_incompleteness\",\"rank_error_incompletness\",\"rank_final\"\n",
        "]\n",
        "for col in needed:\n",
        "    if col not in df.columns:\n",
        "        df[col] = np.nan\n",
        "\n",
        "# Parse date\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "\n",
        "# Parse numeric (handle comma decimals like 69,37)\n",
        "def numify(series_like):\n",
        "    s = pd.Series(series_like, dtype=\"string\") \\\n",
        "          .str.replace(\" \", \"\", regex=False) \\\n",
        "          .str.replace(\",\", \".\", regex=False)\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "df[\"score_dws\"]                   = numify(df[\"score_dws\"])\n",
        "df[\"rank_dws\"]                    = pd.to_numeric(df[\"rank_dws\"], errors=\"coerce\")\n",
        "df[\"rank_error_incompletness\"]    = pd.to_numeric(df[\"rank_error_incompletness\"], errors=\"coerce\")\n",
        "df[\"rank_final\"]                  = pd.to_numeric(df[\"rank_final\"], errors=\"coerce\")\n",
        "df[\"score_missmatch\"]             = numify(df[\"score_missmatch\"])\n",
        "df[\"rank_missmatch\"]              = pd.to_numeric(df[\"rank_missmatch\"], errors=\"coerce\")\n",
        "df[\"score_error_incompleteness\"]  = numify(df[\"score_error_incompleteness\"])\n",
        "\n",
        "# Only rows with valid score & rank\n",
        "df = df.loc[~df[\"score_dws\"].isna() & ~df[\"rank_dws\"].isna()].copy()\n",
        "\n",
        "# Optional date filter\n",
        "if FILTER_DATE:\n",
        "    target_day = pd.to_datetime(FILTER_DATE).date()\n",
        "    df = df[df[\"date\"].dt.date.eq(target_day)]\n",
        "\n",
        "if df.empty:\n",
        "    print(\"No rows to generate (after filtering).\")\n",
        "else:\n",
        "    # =======================\n",
        "    # max rank per date (cohort size proxy)\n",
        "    # =======================\n",
        "    grp = df.dropna(subset=[\"score_dws\"]).groupby(df[\"date\"].dt.date, as_index=True)[\"rank_dws\"]\n",
        "    max_rank_by_date = grp.max().rename(\"max_rank_dws\")\n",
        "    df = df.merge(max_rank_by_date, left_on=df[\"date\"].dt.date, right_index=True, how=\"left\")\n",
        "\n",
        "    df[\"kategori_dws\"] = df[\"score_dws\"].map(kategori_dws)\n",
        "\n",
        "    # =======================\n",
        "    # Skip logic (anti-join by id|name|date)\n",
        "    # =======================\n",
        "    sh = gc.open_by_key(SHEET_ID)\n",
        "    try:\n",
        "        ws_links = sh.worksheet(OUTPUT_TAB)\n",
        "        existing_links = get_as_dataframe(ws_links).dropna(how=\"all\")\n",
        "    except Exception:\n",
        "        ws_links = None\n",
        "        existing_links = pd.DataFrame(columns=[\"ID\",\"name\",\"date\",\"doc_url\"])\n",
        "\n",
        "    if SKIP_IF_HAS_LINK and not existing_links.empty:\n",
        "        ex = existing_links.rename(columns=str.lower).copy()\n",
        "        if \"date\" in ex.columns:\n",
        "            ex[\"date\"] = pd.to_datetime(ex[\"date\"], errors=\"coerce\").dt.date\n",
        "\n",
        "        df[\"date_only\"] = df[\"date\"].dt.date\n",
        "        df[\"__key\"] = (\n",
        "            df[\"id\"].astype(str).str.strip() + \"|\" +\n",
        "            df[\"name\"].astype(str).str.strip() + \"|\" +\n",
        "            df[\"date_only\"].astype(str)\n",
        "        )\n",
        "\n",
        "        ex = ex[[c for c in [\"id\",\"name\",\"date\"] if c in ex.columns]].dropna(how=\"any\")\n",
        "        if not ex.empty:\n",
        "            ex[\"__key\"] = (\n",
        "                ex[\"id\"].astype(str).str.strip() + \"|\" +\n",
        "                ex[\"name\"].astype(str).str.strip() + \"|\" +\n",
        "                ex[\"date\"].astype(str)\n",
        "            )\n",
        "            before = len(df)\n",
        "            df = df[~df[\"__key\"].isin(set(ex[\"__key\"]))].drop(columns=[\"__key\",\"date_only\"])\n",
        "            print(f\"Skip-if-has-link active: removed {before - len(df)} already-generated rows.\")\n",
        "        else:\n",
        "            df = df.drop(columns=[\"date_only\"], errors=\"ignore\")\n",
        "\n",
        "    print(\"Columns now:\", df.columns.tolist())\n",
        "\n",
        "    # =======================\n",
        "    # Create Docs\n",
        "    # =======================\n",
        "    created = []\n",
        "    for row in df.to_dict(\"records\"):\n",
        "        person_id   = fmt_id(row.get(\"id\"))\n",
        "        person_name = (row.get(\"name\") or \"\").strip()\n",
        "        dts         = pd.to_datetime(row.get(\"date\"), errors=\"coerce\")\n",
        "        nice_date   = tanggal_id(dts)\n",
        "\n",
        "        rank_dws  = \"\" if pd.isna(row.get(\"rank_dws\")) else int(row.get(\"rank_dws\"))\n",
        "        max_rank  = \"\" if pd.isna(row.get(\"max_rank_dws\")) else int(row.get(\"max_rank_dws\"))\n",
        "        score_dws = row.get(\"score_dws\")\n",
        "        kat_dws   = row.get(\"kategori_dws\") or \"\"\n",
        "\n",
        "        rank_mm   = row.get(\"rank_missmatch\")\n",
        "        rank_ei   = row.get(\"rank_error_incompletness\")\n",
        "        rank_fin  = row.get(\"rank_final\")\n",
        "        score_mm  = row.get(\"score_missmatch\")\n",
        "        score_err = row.get(\"score_error_incompleteness\")\n",
        "\n",
        "        doc_name   = f\"LKH - {person_name} - {nice_date}\"\n",
        "        new_doc_id = copy_template(doc_name)\n",
        "\n",
        "        # Support both lower/space and UPPERCASE placeholders\n",
        "        mapping = {\n",
        "            # Identity\n",
        "            \"NAMA\": person_name, \"name\": person_name,\n",
        "            \"ID\": person_id, \"id\": person_id,\n",
        "            \"DATE\": nice_date, \"TANGGAL\": nice_date, \"date\": nice_date,\n",
        "\n",
        "            # DWS section\n",
        "            \"RANK_DWS\": rank_dws, \"RANK_DWS\": rank_dws,\n",
        "            \"MAX_RANK_DWS\": max_rank, \"MAX_RANK_DWS\": max_rank,\n",
        "            \"SCORE_DWS\": \"\" if pd.isna(score_dws) else f\"{float(score_dws):.2f}\",\n",
        "            \"KATEGORI_DWS\": kat_dws, \"KATEGORI_DWS\": kat_dws,\n",
        "\n",
        "            # Optional extras (only replaced if present in template)\n",
        "            \"rank_missmatch\": \"\" if pd.isna(rank_mm) else int(rank_mm),\n",
        "            \"rank_error_incompletness\": \"\" if pd.isna(rank_ei) else int(rank_ei),\n",
        "            \"rank_final\": \"\" if pd.isna(rank_fin) else int(rank_fin),\n",
        "            \"score_missmatch\": \"\" if pd.isna(score_mm) else f\"{float(score_mm):.2f}\",\n",
        "            \"score_error_incompleteness\": \"\" if pd.isna(score_err) else f\"{float(score_err):.2f}\",\n",
        "        }\n",
        "\n",
        "        replace_placeholders(new_doc_id, mapping)\n",
        "\n",
        "        created.append({\n",
        "            \"ID\": person_id,\n",
        "            \"name\": person_name,\n",
        "            \"date\": dts.date(),\n",
        "            \"doc_url\": f\"https://docs.google.com/document/d/{new_doc_id}/edit\"\n",
        "        })\n",
        "\n",
        "    links_df = pd.DataFrame(created)\n",
        "    print(f\"Created {len(links_df)} documents.\")\n",
        "\n",
        "    # =======================\n",
        "    # Write/append links tab (de-duplicate by ID+name+date)\n",
        "    # =======================\n",
        "    sh = gc.open_by_key(SHEET_ID)\n",
        "    if ws_links is None:\n",
        "        ws_links = sh.add_worksheet(title=OUTPUT_TAB, rows=200, cols=8)\n",
        "        set_with_dataframe(ws_links, links_df, include_index=False, resize=True)\n",
        "    else:\n",
        "        existing = get_as_dataframe(ws_links).dropna(how=\"all\")\n",
        "        out = pd.concat([existing, links_df], ignore_index=True)\n",
        "\n",
        "        # normalize & dedupe\n",
        "        out.columns = [str(c).strip() for c in out.columns]\n",
        "        if \"date\" in out.columns:\n",
        "            out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\").dt.date\n",
        "        dedupe_keys = [c for c in [\"ID\",\"name\",\"date\"] if c in out.columns]\n",
        "        if dedupe_keys:\n",
        "            out = out.drop_duplicates(subset=dedupe_keys, keep=\"first\")\n",
        "\n",
        "        ws_links.clear()\n",
        "        set_with_dataframe(ws_links, out, include_index=False, resize=True)\n",
        "\n",
        "    print(\"Links updated:\", OUTPUT_TAB)\n"
      ],
      "metadata": {
        "id": "Aw49lKTt2bJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d45a6cb-6f72-4ba7-ef62-d30685a6da25"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Template is accessible.\n",
            "Columns now: ['key_0', 'id', 'name', 'date', 'score_error_incompletness', 'score_dws', 'score_missmatch', 'rank_dws', 'rank_missmatch', 'rank_error_incompletness', 'rank_rank', 'score_error_incompleteness', 'rank_final', 'max_rank_dws', 'kategori_dws']\n",
            "Created 189 documents.\n",
            "Links updated: Laporan Kinerja Harian (LKH)\n"
          ]
        }
      ]
    }
  ]
}